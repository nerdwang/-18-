{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c076b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"C:\\\\Users\\\\86182\\\\Desktop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185f9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a84ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = pd.read_csv(\"True.csv\")\n",
    "false = pd.read_csv(\"Fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0535b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "true['category'] = 1\n",
    "false['category'] = 0\n",
    "df = pd.concat([true,false])\n",
    "df['text'] = df['text'] + \" \" + df['title']\n",
    "del df['date']\n",
    "del df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79167c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008cd761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['text']=df['text'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e51a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['subject']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5e614",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcbc37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size = 0.3, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee225315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a538e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vectorizer, classifier, X_train, X_test, y_train, y_test):\n",
    "    pipe = Pipeline([('vector', vectorizer),\n",
    "                    ('model', classifier)])\n",
    "    model = pipe.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuarcy: {}\".format(round(accuracy_score(y_test, y_pred)*100,2)))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix: \\n\", cm)\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6373567e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " LGBMClassifier()\n",
      "***********Usng TFIDF Vectorizer****************\n",
      "[LightGBM] [Info] Number of positive: 15016, number of negative: 16412\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.944234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 754555\n",
      "[LightGBM] [Info] Number of data points in the train set: 31428, number of used features: 5000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.477791 -> initscore=-0.088896\n",
      "[LightGBM] [Info] Start training from score -0.088896\n",
      "Accuarcy: 99.74\n",
      "Confusion Matrix: \n",
      " [[7049   20]\n",
      " [  15 6386]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7069\n",
      "           1       1.00      1.00      1.00      6401\n",
      "\n",
      "    accuracy                           1.00     13470\n",
      "   macro avg       1.00      1.00      1.00     13470\n",
      "weighted avg       1.00      1.00      1.00     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [lgb.LGBMClassifier()]\n",
    "for classifier in classifiers:\n",
    "    print(\"\\n\\n\", classifier)\n",
    "    print(\"***********Usng TFIDF Vectorizer****************\")\n",
    "    get_prediction(TfidfVectorizer(max_features=5000,stop_words='english'), classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab59de9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " SVC()\n",
      "***********Usng TFIDF Vectorizer****************\n",
      "Accuarcy: 99.28\n",
      "Confusion Matrix: \n",
      " [[7012   57]\n",
      " [  40 6361]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7069\n",
      "           1       0.99      0.99      0.99      6401\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [SVC()]\n",
    "for classifier in classifiers:\n",
    "    print(\"\\n\\n\", classifier)\n",
    "    print(\"***********Usng TFIDF Vectorizer****************\")\n",
    "    get_prediction(TfidfVectorizer(max_features=5000,stop_words='english'), classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d56441d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27cf1042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " LinearSVC()\n",
      "***********Usng TFIDF Vectorizer****************\n",
      "Accuarcy: 99.53\n",
      "Confusion Matrix: \n",
      " [[7031   38]\n",
      " [  25 6376]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      7069\n",
      "           1       0.99      1.00      1.00      6401\n",
      "\n",
      "    accuracy                           1.00     13470\n",
      "   macro avg       1.00      1.00      1.00     13470\n",
      "weighted avg       1.00      1.00      1.00     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LinearSVC()]\n",
    "for classifier in classifiers:\n",
    "    print(\"\\n\\n\", classifier)\n",
    "    print(\"***********Usng TFIDF Vectorizer****************\")\n",
    "    get_prediction(TfidfVectorizer(max_features=5000,stop_words='english'), classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35619b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
